# -*- coding: utf-8 -*-
"""Harry Potter_Spells Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gWS6eG1lIo23zbZGN_dmFxn_zDUkJ_aO
"""

from google.colab import drive
drive.mount("/content/drive")

ls "/content/drive/MyDrive/Colab Notebooks/Harry Potter"

import nltk
nltk.download("popular")
nltk.download("all-corpora")

import nltk
from nltk.corpus import PlaintextCorpusReader

corpus_root = "/content/drive/MyDrive/Colab Notebooks/Harry Potter"
wordlists = PlaintextCorpusReader(corpus_root, ".*")

books = wordlists.fileids()
print(books)

import nltk
from wordcloud import STOPWORDS

dataset = wordlists.raw('Harry Potter and the Goblet of Fire.txt')

tokens = dataset.split(' ')
clean_tokens = tokens[:]

for token in tokens:
  if token.lower() in STOPWORDS:
    clean_tokens.remove(token)

freq = nltk.FreqDist(clean_tokens)

cfd = nltk.ConditionalFreqDist((fileid,word)
    for fileid in books
    for word in wordlists.words(fileid)
)

findSpell = ["Crucio"]
cfd.tabulate(conditions=books, samples=findSpell)

import nltk
textText = wordlists.words('Harry Potter and the Goblet of Fire.txt')
single = nltk.text.Text(textText)
print(single)

single.concordance("Crucio",lines=100)

cfd = nltk.ConditionalFreqDist(
           (target, fileid[:30])
           for fileid in wordlists.fileids()
           for w in wordlists.words(fileid)

           for target in ['crucio','imperio','avada']
           if w.lower().startswith(target))
cfd.plot()